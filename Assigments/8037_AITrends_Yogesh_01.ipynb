{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f90e013",
      "metadata": {
        "id": "6f90e013"
      },
      "outputs": [],
      "source": [
        "# Intialization\n",
        "import os\n",
        "import sys\n",
        "\n",
        "os.environ[\"SPARK_HOME\"] = \"/home/talentum/spark\"\n",
        "os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
        "# In below two lines, use /usr/bin/python2.7 if you want to use Python 2\n",
        "os.environ[\"PYSPARK_PYTHON\"] = \"/usr/bin/python3.6\"\n",
        "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"/usr/bin/python3\"\n",
        "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/py4j-0.10.7-src.zip\")\n",
        "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/pyspark.zip\")\n",
        "\n",
        "# NOTE: Whichever package you want mention here.\n",
        "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.11:0.6.0 pyspark-shell'\n",
        "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-avro_2.11:2.4.0 pyspark-shell'\n",
        "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.11:0.6.0,org.apache.spark:spark-avro_2.11:2.4.3 pyspark-shell'\n",
        "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.11:0.6.0,org.apache.spark:spark-avro_2.11:2.4.0 pyspark-shell'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b1fee50",
      "metadata": {
        "id": "8b1fee50"
      },
      "outputs": [],
      "source": [
        "#Entrypoint 2.x\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"Spark SQL basic example\").enableHiveSupport().getOrCreate()\n",
        "\n",
        "# On yarn:\n",
        "# spark = SparkSession.builder.appName(\"Spark SQL basic example\").enableHiveSupport().master(\"yarn\").getOrCreate()\n",
        "# specify .master(\"yarn\")\n",
        "\n",
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50f9282a",
      "metadata": {
        "id": "50f9282a",
        "outputId": "0ed6c0eb-f9ff-43b5-b19a-8e50e6bfef8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hadoop http://hortonworks.com/,http://hortonworks.com/download/,http://hortonworks.com/community/,http://hortonworks.com/kb,http://hortonworks.com/about-us/,http://hortonworks.com/resources/,http://hortonworks.com/webinars/,http://hortonworks.com/resources/,http://hortonworks.com/hadoop-training/\n",
            "webinars http://hortonworks.com/\n",
            "enterprise http://hortonworks.com/,http://hortonworks.com/products/hortonworksdataplatform/,http://hortonworks.com/about-us/contact-us/\n",
            "team http://hortonworks.com/\n",
            "reliability http://hortonworks.com/,http://hortonworks.com/resources/\n",
            "feed http://hortonworks.com/products/,http://hortonworks.com/kb,http://hortonworks.com/resources/\n",
            "board http://hortonworks.com/products/\n",
            "password http://hortonworks.com/products/hortonworksdataplatform/,http://hortonworks.com/community/\n",
            "hdp http://hortonworks.com/get-started/,http://hortonworks.com/download/,http://hortonworks.com/about-us/contact-us/,http://hortonworks.com/events/,http://hortonworks.com/webinars/,http://hortonworks.com/hadoop-training/\n",
            "presentations http://hortonworks.com/download/,http://hortonworks.com/resources/\n",
            "connect http://hortonworks.com/community/\n",
            "knowledgebase http://hortonworks.com/community/\n",
            "platform http://hortonworks.com/kb,http://hortonworks.com/events/,http://hortonworks.com/resources/\n",
            "support http://hortonworks.com/about-us/contact-us/\n",
            "training http://hortonworks.com/resources/,http://hortonworks.com/events/,http://hortonworks.com/hadoop-training/\n",
            "webinar http://hortonworks.com/webinars/\n",
            "instructor-led http://hortonworks.com/hadoop-training/\n",
            "articles http://hortonworks.com/,http://hortonworks.com/community/\n",
            "download http://hortonworks.com/,http://hortonworks.com/download/,http://hortonworks.com/community/\n",
            "hortonworks http://hortonworks.com/products/,http://hortonworks.com/about-us/,http://hortonworks.com/about-us/contact-us/\n",
            "services http://hortonworks.com/products/,http://hortonworks.com/resources/\n",
            "core http://hortonworks.com/products/,http://hortonworks.com/kb\n",
            "deployments http://hortonworks.com/products/,http://hortonworks.com/get-started/\n",
            "required http://hortonworks.com/products/\n",
            "apache http://hortonworks.com/products/hortonworksdataplatform/,http://hortonworks.com/about-us/\n",
            "directors http://hortonworks.com/products/hortonworksdataplatform/,http://hortonworks.com/about-us/\n",
            "data http://hortonworks.com/get-started/\n",
            "downloads http://hortonworks.com/get-started/,http://hortonworks.com/events/\n",
            "founders http://hortonworks.com/get-started/,http://hortonworks.com/about-us/\n",
            "register http://hortonworks.com/download/\n",
            "videos http://hortonworks.com/download/,http://hortonworks.com/resources/,http://hortonworks.com/events/,http://hortonworks.com/webinars/\n",
            "about http://hortonworks.com/about-us/\n",
            "contact http://hortonworks.com/about-us/contact-us/\n",
            "blog http://hortonworks.com/resources/\n",
            "certification http://hortonworks.com/hadoop-training/\n",
            "courses http://hortonworks.com/hadoop-training/\n",
            "learn http://hortonworks.com/hadoop-training/\n"
          ]
        }
      ],
      "source": [
        "# set the path\n",
        "file_path = \"file:///home/talentum/test-jupyter/evaluation/Lab1/hortonworks.txt\"\n",
        "# read the path\n",
        "fileRDD = sc.textFile(file_path)\n",
        "# split on ','\n",
        "splitRDD = fileRDD.map(lambda line: line.split(','))\n",
        "# create flatmap on line[0] which is url as value and keys are remaining words\n",
        "mapRDD = splitRDD.flatMap(lambda line: ((word, line[0]) for word in line[1:]))\n",
        "# reduce by key\n",
        "finalRDD = mapRDD.reduceByKey(lambda url1, url2: url1 + ',' + url2)\n",
        "# print the key, value\n",
        "for key, value in finalRDD.collect():\n",
        "    print(key, value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9484c0f1",
      "metadata": {
        "id": "9484c0f1",
        "outputId": "83e98dae-c304-4047-dfa0-25340b03b14d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------+--------------------+\n",
            "|          word|                urls|\n",
            "+--------------+--------------------+\n",
            "|        hadoop|http://hortonwork...|\n",
            "|      webinars|http://hortonwork...|\n",
            "|    enterprise|http://hortonwork...|\n",
            "|          team|http://hortonwork...|\n",
            "|   reliability|http://hortonwork...|\n",
            "|          feed|http://hortonwork...|\n",
            "|         board|http://hortonwork...|\n",
            "|      password|http://hortonwork...|\n",
            "|           hdp|http://hortonwork...|\n",
            "| presentations|http://hortonwork...|\n",
            "|       connect|http://hortonwork...|\n",
            "| knowledgebase|http://hortonwork...|\n",
            "|      platform|http://hortonwork...|\n",
            "|       support|http://hortonwork...|\n",
            "|      training|http://hortonwork...|\n",
            "|       webinar|http://hortonwork...|\n",
            "|instructor-led|http://hortonwork...|\n",
            "|      articles|http://hortonwork...|\n",
            "|      download|http://hortonwork...|\n",
            "|   hortonworks|http://hortonwork...|\n",
            "+--------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.types import StructType, StructField, StringType\n",
        "\n",
        "schema = StructType([\n",
        "    StructField(\"word\", StringType(), True),\n",
        "    StructField(\"urls\", StringType(), True)\n",
        "])\n",
        "\n",
        "# Convert the RDD to a DataFrame\n",
        "df = spark.createDataFrame(finalRDD, schema)\n",
        "\n",
        "df.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}